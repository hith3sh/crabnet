# Implementation Plan for Issue #295: Finlex - Newsfeed v2 Content Change Detection

---

## Overview

Test and deploy Finlex table for Newsfeed v2 content hash detection feature.

**Parent Issue:** #294 (Newsfeed v2 - Add Finnish sources with content change detection)
**Table:** `finlex` (Finnish legislation, government proposals, court cases)
**Implementation:** Use existing Newsfeed v2 infrastructure (Issue #294)

---

## Pre-requisites

**From Issue #294:**
- [x] Database migration completed (content_hash column added to newsfeed_items)
- [x] Model updates completed (NewsfeedItem, NewsfeedItemTranslation, NewsfeedChangeAnalysis)
- [x] ETL processor completed (NewsfeedPopulatorETL with content_hash support)
- [x] CLI integration completed (newsfeed_populator command)
- [x] Configuration completed (NEWSFEED_TIME_WINDOWS, SOURCE_COUNTRY_MAP)

**Current State:**
- All infrastructure is in place on branch `feat/294-newsfeed-v2-content-hash`
- No new database migrations needed (content_hash column already exists)
- No new ETL processor code needed (NewsfeedPopulatorETL already supports content_hash)
- Finlex table is ready to be queried

---

## Implementation Steps

### Step 1: Verify Finlex Table Structure

**Action:**
- Query `finlex` table to confirm it has required columns: `content_hash`, `as_of`, `url`, `published_at`, `title`
- Verify `finlex` table exists in database schema
- Check that `content_hash` is populated for Finlex records

**SQL Query:**
```sql
SELECT column_name
FROM information_schema.columns
WHERE table_name = 'finlex'
ORDER BY ordinal_position;
```

**Expected Result:** Should see columns: `content_hash`, `as_of`, `url`, `published_at`, `title`

---

### Step 2: Test Newsfeed Populator with Finlex

**Action:**
- Run `newsfeed_populator` CLI command with Finlex table in dry-run mode
- Verify it queries Finlex table correctly
- Check that it uses `as_of` window filtering (last 7 days by default)
- Confirm content_hash is included in results

**Command:**
```bash
uv run python bin/etl_runner.py newsfeed_populator \
  --table-name finlex \
  --dry-run
```

**Expected Output:** Should show:
- Candidate documents queried from Finlex
- Content hash values included
- Newsfeed items that would be created (but not actually due to dry-run)

---

### Step 3: Validate Content Change Detection

**Action:**
- Query Finlex table for documents with multiple content_hash versions
- Verify that Newsfeed v2 can detect when content changes
- Ensure NOT EXISTS clause correctly uses content_hash in deduplication

**SQL Query:**
```sql
SELECT 
    title,
    published_at,
    COUNT(*) as versions,
    ARRAY_AGG(content_hash) as content_hashes
FROM finlex
WHERE title IN (
    SELECT title FROM finlex
    GROUP BY title
    HAVING COUNT(*) > 1
)
LIMIT 5;
```

**Expected Result:** Finlex documents with multiple versions exist (content changes detected)

---

### Step 4: Production Deployment

**Action:**
- Run `newsfeed_populator` CLI command with Finlex table in production mode (no dry-run)
- Verify it creates newsfeed_items entries correctly
- Confirm content_hash values are stored
- Check that relevancy scores and categories are appropriate

**Command:**
```bash
uv run python bin/etl_runner.py newsfeed_populator \
  --table-name finlex
```

**Expected Result:** Newsfeed items created in database with:
- Correct content_hash values
- Proper LLM summaries
- Accounting categories
- Relevancy scores
- Multi-language translations (en, fi, sv)

---

## Files Modified

### No new files needed!

All implementation uses **existing** Newsfeed v2 infrastructure from Issue #294:

**1. Database Migrations**
- `packages/common_lib/migrations/versions/add_content_hash_columns_alembic.py` - Created in Issue #294
- Adds `content_hash` column to `newsfeed_items`
- Creates `newsfeed_change_analysis` table
- Updates unique constraint to include `content_hash`

**2. Model Updates**
- `packages/scrape_configs/src/scrape_configs/models/newsfeed.py` - Updated in Issue #294
- `NewsfeedItem` class has `content_hash = Column(String(64), nullable=True`
- `__table_args__` includes content_hash in unique constraint
- `NewsfeedItemTranslation` class has `content_hash = Column(String(64), nullable=True`
- `__table_args__` includes content_hash in unique constraint

**3. ETL Processor**
- `packages/etl/src/etl/processors/newsfeed_populator.py` - Updated in Issue #294
- `get_records()` method includes `content_hash` in SELECT clause
- `get_records()` uses `as_of_window_days` filtering
- `get_records()` includes `content_hash` in NOT EXISTS subquery
- `process_record()` method passes `content_hash` to NewsfeedItem constructor

**4. CLI Integration**
- `bin/etl_runner.py` - Updated in Issue #294
- `newsfeed_populator` command available
- Supports `--as-of-window-days` parameter
- Supports `--start-date`, `--end-date`, `--dry-run` parameters

**5. Configuration**
- `NEWSFEED_TIME_WINDOWS` configuration added in Issue #294
- `SOURCE_COUNTRY_MAP` includes `"finlex": "fi"` entry
- Both are available to the ETL processor

---

## Branch Strategy

### Option 1: Work in Current Branch âœ…
- Continue on branch `feat/294-newsfeed-v2-content-hash`
- Add Issue #295 to AGENTS.md as "started"
- Test and deploy Finlex
- Mark Issue #295 as "complete" when done

**Pros:**
- All work stays in one branch
- Easy to review (single PR with #294)
- Consistent with Issue #294 implementation

**Cons:**
- Finlex is specific to Issue #295, but branch also contains Issue #294
- Harder to separate Finlex-specific changes if needed later

### Option 2: Create Dedicated Branch
- Create new branch: `feat/295-finlex-implementation`
- Add implementation for Finlex-specific changes (if any)
- Merge back to Issue #294 branch when complete

**Pros:**
- Clear separation of concerns
- Easier to review Finlex implementation independently
- Can merge back to #294 branch

**Cons:**
- More git branches to manage
- Extra merge operations needed

---

## Testing Plan

### 1. Pre-Deployment Testing

**Check Finlex Table:**
```sql
SELECT 
    COUNT(*) as total_records,
    COUNT(DISTINCT content_hash) as unique_hashes,
    COUNT(DISTINCT url) as unique_urls
FROM finlex
WHERE as_of >= CURRENT_DATE - INTERVAL '30 days';
```

### 2. Dry Run

**Test newsfeed_populator with dry-run:**
```bash
# Check recent Finlex records
psql -d scraping -c "
SELECT 
    title,
    as_of,
    content_hash
FROM finlex
ORDER BY as_of DESC
LIMIT 5;
"

# Test dry-run
uv run python bin/etl_runner.py newsfeed_populator \
  --table-name finlex \
  --dry-run
```

**Verify Output:**
- Should query recent Finlex records
- Should show what would be created
- No actual database writes

### 3. Production Run (Small Scale)

**Run newsfeed_populator for Finlex:**
```bash
uv run python bin/etl_runner.py newsfeed_populator \
  --table-name finlex
```

**Verify Results:**
```sql
SELECT 
    COUNT(*) as created_items,
    COUNT(*) as created_with_content_hash,
    COUNT(DISTINCT title) as unique_titles
FROM newsfeed_items
WHERE source = 'finlex'
AND as_of >= CURRENT_DATE - INTERVAL '7 days';
```

### 4. Content Change Detection Verification

**Query documents with multiple versions:**
```sql
SELECT 
    f.title,
    COUNT(*) as version_count,
    ARRAY_AGG(f.content_hash ORDER BY f.as_of DESC) as content_hashes
FROM finlex f
WHERE f.title IN (
    SELECT title FROM finlex
    GROUP BY title
    HAVING COUNT(*) > 1
)
LIMIT 5;
```

**Expected Result:** Should show Finlex documents that have been updated multiple times, proving content change detection works.

---

## Deployment Checklist

- [ ] Verify Finlex table has `content_hash` column
- [ ] Verify Finlex table has `as_of` column
- [ ] Test newsfeed_populator dry-run with Finlex
- [ ] Test newsfeed_populator production with Finlex (small batch)
- [ ] Verify newsfeed_items created with content_hash values
- [ ] Verify content change detection works (documents with updates)
- [ ] Check for errors or warnings
- [ ] Validate LLM summaries in multiple languages
- [ ] Verify Azure Search chunk_ids are populated
- [ ] Document deployment process

---

## Rollback Plan

If Finlex deployment causes issues:

**1. Stop newsfeed_populator**
```bash
# Disable Finlex Newsfeed v2 in Airflow
# Or remove from NEWSFEED_TIME_WINDOWS if using config
```

**2. Delete created newsfeed_items:**
```sql
DELETE FROM newsfeed_items
WHERE source = 'finlex'
AND created_at >= CURRENT_DATE - INTERVAL '1 day';
```

**3. Fix database issues:**
- Check for duplicate newsfeed_items
- Re-run newsfeed_populator with deduplication fix

---

## Notes

- Finlex table is part of Issue #294 (Newsfeed v2) but tested independently here
- Newsfeed v2 infrastructure is production-ready (Issue #294 is complete)
- All database migrations and ETL processor changes are in place
- This is a **testing/deployment task** for a specific table

---

## Success Criteria

- [ ] Newsfeed items created for Finlex
- [ ] content_hash values populated correctly
- [ ] Content changes detected (same title, different content_hash)
- [ ] LLM summaries generated in en, fi, sv
- [ ] Accounting categories assigned
- [ ] Relevancy scores assigned
- [ ] No duplicates created
- [ ] No errors or warnings

---

## Next Steps

After Finlex deployment:

1. **Continue with other sub-issues:**
   - Issue #296 (KILA - Accounting Board)
   - Issue #297 (TELP - Employment/Labor Guidance)
   - Issue #298 (Kela - Social Insurance)

2. **Enhance Newsfeed v2:**
   - Add accounting category mapping for legislative content
   - Implement relevancy scoring adjustments for Finlex
   - Add source-specific time windows

3. **Review Issue #294:**
   - Is Newsfeed v2 working as expected for all sources?
   - Are there any bugs or improvements needed?

---

## Ready When You Are

I've created a comprehensive plan for testing and deploying Finlex with Newsfeed v2 content hash detection. All infrastructure is already in place from Issue #294.

**Current Status:**
- Issue #294 (Newsfeed v2): Complete âœ…
- Issue #295 (Finlex Testing & Deployment): ðŸ”„ **OPEN** - Plan created
- Branch: `feat/294-newsfeed-v2-content-hash` (contains all Newsfeed v2 infrastructure)

**Implementation:** All code exists. This is a **testing and deployment task** using the existing framework.

**Would you like me to:**
1. Start implementing Finlex testing according to the plan?
2. Modify the existing branch (add Issue #295 to AGENTS.md, create test files)?
3. Create a dedicated branch for Finlex implementation?

Let me know! ðŸ˜¸

---